{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geodb.model\n",
    "from geodb.model import GPSPoint, db_url, GPSTrack, clone_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(db_url(), echo=False)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-11-16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-11-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-11-24</td>\n",
       "      <td>6640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>5741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-11-27</td>\n",
       "      <td>6016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>10589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>7333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>6069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>3812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>4763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>6199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>4111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-12-05</td>\n",
       "      <td>8390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>7911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-12-07</td>\n",
       "      <td>7938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-12-08</td>\n",
       "      <td>7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-12-09</td>\n",
       "      <td>4971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>4136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2019-12-22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  count\n",
       "0   2019-11-01      1\n",
       "1   2019-11-02      2\n",
       "2   2019-11-03      1\n",
       "3   2019-11-04      1\n",
       "4   2019-11-05      1\n",
       "5   2019-11-06      2\n",
       "6   2019-11-07      1\n",
       "7   2019-11-09      3\n",
       "8   2019-11-10      3\n",
       "9   2019-11-11      1\n",
       "10  2019-11-16      2\n",
       "11  2019-11-17      1\n",
       "12  2019-11-18      2\n",
       "13  2019-11-19      1\n",
       "14  2019-11-20     93\n",
       "15  2019-11-21     94\n",
       "16  2019-11-22    850\n",
       "17  2019-11-23   2996\n",
       "18  2019-11-24   6640\n",
       "19  2019-11-25   5741\n",
       "20  2019-11-26   5500\n",
       "21  2019-11-27   6016\n",
       "22  2019-11-28  10589\n",
       "23  2019-11-29   7333\n",
       "24  2019-11-30   6069\n",
       "25  2019-12-01   3812\n",
       "26  2019-12-02   4763\n",
       "27  2019-12-03   6199\n",
       "28  2019-12-04   4111\n",
       "29  2019-12-05   8390\n",
       "30  2019-12-06   7911\n",
       "31  2019-12-07   7938\n",
       "32  2019-12-08   7789\n",
       "33  2019-12-09   4971\n",
       "34  2019-12-10   4136\n",
       "35  2019-12-11     23\n",
       "36  2019-12-13      1\n",
       "37  2019-12-14      2\n",
       "38  2019-12-15      2\n",
       "39  2019-12-16      1\n",
       "40  2019-12-18      1\n",
       "41  2019-12-19      1\n",
       "42  2019-12-20      2\n",
       "43  2019-12-21      4\n",
       "44  2019-12-22      4\n",
       "45  2019-12-23      7\n",
       "46  2019-12-24      3\n",
       "47  2019-12-25      2\n",
       "48  2019-12-26      4\n",
       "49  2019-12-27      2\n",
       "50  2019-12-28      3\n",
       "51  2019-12-29      2\n",
       "52  2019-12-30      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select date(time), count(*) from point\n",
    "where time > '2019-11-01'\n",
    "group by 1\n",
    "order by 1\n",
    "\"\"\"\n",
    "display(pd.read_sql_query(query, engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find tracks for day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2019-11-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12744</td>\n",
       "      <td>2019-12-01 05:11:29+00:00</td>\n",
       "      <td>2019-12-01 05:12:36+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1522</td>\n",
       "      <td>2019-12-01 08:54:26+00:00</td>\n",
       "      <td>2019-12-01 08:54:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12692</td>\n",
       "      <td>2019-11-30 00:49:21+00:00</td>\n",
       "      <td>2019-11-30 00:54:11+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12686</td>\n",
       "      <td>2019-11-30 00:04:24+00:00</td>\n",
       "      <td>2019-11-30 00:06:49+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12756</td>\n",
       "      <td>2019-12-01 10:20:40+00:00</td>\n",
       "      <td>2019-12-02 00:35:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2802</td>\n",
       "      <td>2019-12-01 07:37:34+00:00</td>\n",
       "      <td>2019-12-01 07:37:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>12675</td>\n",
       "      <td>2019-11-29 07:52:30+00:00</td>\n",
       "      <td>2019-11-29 07:59:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>12712</td>\n",
       "      <td>2019-11-30 06:37:32+00:00</td>\n",
       "      <td>2019-11-30 07:12:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>12742</td>\n",
       "      <td>2019-12-01 04:52:27+00:00</td>\n",
       "      <td>2019-12-01 04:58:22+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>12699</td>\n",
       "      <td>2019-11-30 01:49:43+00:00</td>\n",
       "      <td>2019-11-30 02:09:51+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                  min_time                  max_time\n",
       "0    12744 2019-12-01 05:11:29+00:00 2019-12-01 05:12:36+00:00\n",
       "1     1522 2019-12-01 08:54:26+00:00 2019-12-01 08:54:26+00:00\n",
       "2    12692 2019-11-30 00:49:21+00:00 2019-11-30 00:54:11+00:00\n",
       "3    12686 2019-11-30 00:04:24+00:00 2019-11-30 00:06:49+00:00\n",
       "4    12756 2019-12-01 10:20:40+00:00 2019-12-02 00:35:14+00:00\n",
       "..     ...                       ...                       ...\n",
       "190   2802 2019-12-01 07:37:34+00:00 2019-12-01 07:37:34+00:00\n",
       "191  12675 2019-11-29 07:52:30+00:00 2019-11-29 07:59:21+00:00\n",
       "192  12712 2019-11-30 06:37:32+00:00 2019-11-30 07:12:21+00:00\n",
       "193  12742 2019-12-01 04:52:27+00:00 2019-12-01 04:58:22+00:00\n",
       "194  12699 2019-11-30 01:49:43+00:00 2019-11-30 02:09:51+00:00\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bracket_query = \"\"\"\n",
    "select track.id, min(time) as min_time, max(time) as max_time from track\n",
    "join point on track_id = track.id\n",
    "where track.parent_id is null\n",
    "group by track.id\n",
    "having abs(date(min(time)) - %(date)s) < 2  or abs(date(max(time)) - %(date)s) < 2\n",
    "\"\"\"\n",
    "display(pd.read_sql_query(bracket_query, engine, params={'date': date}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bracket_tracks = [session.query(GPSTrack).get(int(t)) \n",
    "                  for t in pd.read_sql_query(bracket_query, engine, params={'date': date})[['id']].values]\n",
    "len(bracket_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_tracks = [t for t in bracket_tracks \n",
    "              if str(t.start.localtime.date()) == date or str(t.end.localtime.date()) == date]\n",
    "len(day_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2019-11-29.json.gz',\n",
       " '2019-11-30 2.json.gz',\n",
       " '2019-12-01.json.gz',\n",
       " None,\n",
       " 'inreach.gpx'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([t.filename for t in day_tracks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1, Nachisan',\n",
       " '156-1, Nachisan',\n",
       " '2, Tsukiji 6-Chōme',\n",
       " '396, Nachisan',\n",
       " '447, Nachisan',\n",
       " 'Aneel Nazareth (9931878)',\n",
       " 'Daimonzaka',\n",
       " 'Hotel Kuu Kyoto (ホテル空)',\n",
       " 'Kii-Katsuura Station (紀伊勝浦駅)',\n",
       " 'Kumano Nachi Taisha (熊野那智大社)',\n",
       " 'Kyoto Beer Lab (京都ビアラボ)',\n",
       " 'Nachi Falls (那智の瀧)',\n",
       " 'Nachisan',\n",
       " None,\n",
       " 'RIO',\n",
       " 'Seiganto-ji',\n",
       " 'Shingū',\n",
       " 'Shinkansen Kyoto Station (東海道新幹線 京都駅)',\n",
       " 'Shinkansen Nagoya Station (東海道新幹線 名古屋駅)',\n",
       " 'Three Story pagoda',\n",
       " 'Unknown Place',\n",
       " 'Veg Out',\n",
       " '勝浦駅 バス停',\n",
       " '南紀勝浦温泉 万清楼',\n",
       " '熊野交通 勝浦駅前出札所',\n",
       " '那智の滝前バス停'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([t.name for t in day_tracks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.date(2019, 11, 29), datetime.date(2019, 11, 30)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([t.start.localtime.date() for t in day_tracks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker, MarkerCluster,\n",
    "    Polyline, \n",
    "    Popup,\n",
    "    GeoJSON,\n",
    "    LayersControl,\n",
    "    basemaps,\n",
    "    CircleMarker\n",
    ")\n",
    "from ipywidgets import HTML\n",
    "\n",
    "from traitlets import link, Tuple\n",
    "from sidecar import Sidecar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marker(t):\n",
    "    marker = Marker(location=t.points[0].lat_lon)\n",
    "    marker.popup = HTML(f\"{t.id}: {t.name}\")\n",
    "    return marker\n",
    "\n",
    "def add_track(m, t, **kwargs):\n",
    "        l = t.as_polyline(\n",
    "            fill=False,\n",
    "            **kwargs\n",
    "        )\n",
    "        m.add_layer(l)\n",
    "        l.popup = HTML(f\"{t.id}: {t.name or t.filename}<br/>{t.points[0].time} - {t.points[-1].time}\")\n",
    "\n",
    "def bounds(lat_lons):\n",
    "    lats, lons = zip(*lat_lons)\n",
    "    return ((min(lats), min(lons)), (max(lats), max(lons)))\n",
    "        \n",
    "def center(b):\n",
    "    return ((b[0][0] + b[1][0])/2, (b[0][1] + b[1][1])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = Sidecar(title='Map')\n",
    "\n",
    "m = Map(center=center(bounds([p.lat_lon for t in day_tracks for p in t.points])), \n",
    "        zoom=2, close_popup_on_click=False)\n",
    "m.layer_control = LayersControl(position='topright')\n",
    "m.add_control(m.layer_control)\n",
    "m.target_bounds = Tuple()\n",
    "\n",
    "markers = []\n",
    "for track in day_tracks:\n",
    "    if len(track.points) == 1 and track.name is not None:\n",
    "        markers.append(marker(track))\n",
    "    else:\n",
    "        add_track(m, track)\n",
    "m.add_layer(MarkerCluster(markers=markers))\n",
    "\n",
    "with sc:\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intervaltree import IntervalTree, Interval\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_tree = IntervalTree()\n",
    "for t in day_tracks:\n",
    "    start = t.start.time\n",
    "    end = t.end.time\n",
    "    if start == end:\n",
    "        end += timedelta(seconds=1)\n",
    "    interval_tree.addi(start, end, {t})\n",
    "interval_tree.split_overlaps()\n",
    "interval_tree.merge_equals(data_reducer=lambda a, b: a.union(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"delete from track where parent_id is not null\")\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interval_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty interval 2019-11-29 23:02:14+00:00 - 2019-11-29 23:02:18+00:00\n",
      "empty interval 2019-11-29 23:24:52+00:00 - 2019-11-29 23:24:55+00:00\n",
      "empty interval 2019-11-29 23:57:08+00:00 - 2019-11-29 23:57:14+00:00\n",
      "empty interval 2019-11-30 00:00:08+00:00 - 2019-11-30 00:00:13+00:00\n",
      "empty interval 2019-11-30 00:06:49+00:00 - 2019-11-30 00:06:51+00:00\n",
      "empty interval 2019-11-30 00:09:25+00:00 - 2019-11-30 00:09:29+00:00\n",
      "empty interval 2019-11-30 00:49:17+00:00 - 2019-11-30 00:49:21+00:00\n",
      "empty interval 2019-11-30 01:06:54+00:00 - 2019-11-30 01:06:57+00:00\n",
      "empty interval 2019-11-30 01:13:05+00:00 - 2019-11-30 01:13:09+00:00\n",
      "empty interval 2019-11-30 01:20:23+00:00 - 2019-11-30 01:20:26+00:00\n",
      "empty interval 2019-11-30 01:27:11+00:00 - 2019-11-30 01:27:16+00:00\n",
      "empty interval 2019-11-30 02:35:58+00:00 - 2019-11-30 02:37:57+00:00\n",
      "empty interval 2019-11-30 03:17:52+00:00 - 2019-11-30 03:18:52+00:00\n",
      "empty interval 2019-11-30 03:18:53+00:00 - 2019-11-30 03:18:56+00:00\n",
      "empty interval 2019-11-30 03:23:37+00:00 - 2019-11-30 03:24:08+00:00\n",
      "empty interval 2019-11-30 03:44:36+00:00 - 2019-11-30 03:44:43+00:00\n",
      "empty interval 2019-11-30 04:14:12+00:00 - 2019-11-30 04:16:19+00:00\n",
      "empty interval 2019-11-30 06:15:02+00:00 - 2019-11-30 06:15:06+00:00\n",
      "empty interval 2019-11-30 06:29:44+00:00 - 2019-11-30 06:29:51+00:00\n",
      "empty interval 2019-11-30 06:37:30+00:00 - 2019-11-30 06:37:32+00:00\n",
      "empty interval 2019-11-30 07:15:09+00:00 - 2019-11-30 07:15:24+00:00\n",
      "empty interval 2019-11-30 07:17:16+00:00 - 2019-11-30 07:17:26+00:00\n",
      "empty interval 2019-11-30 07:17:50+00:00 - 2019-11-30 07:17:55+00:00\n",
      "empty interval 2019-11-30 07:27:42+00:00 - 2019-11-30 07:27:45+00:00\n",
      "empty interval 2019-11-30 07:30:38+00:00 - 2019-11-30 07:30:45+00:00\n",
      "empty interval 2019-11-30 07:44:26+00:00 - 2019-11-30 07:44:36+00:00\n",
      "empty interval 2019-11-30 07:51:06+00:00 - 2019-11-30 07:51:36+00:00\n",
      "empty interval 2019-11-30 08:12:46+00:00 - 2019-11-30 08:12:53+00:00\n",
      "empty interval 2019-11-30 08:22:03+00:00 - 2019-11-30 08:22:34+00:00\n"
     ]
    }
   ],
   "source": [
    "intervals = []\n",
    "for interval in sorted(interval_tree):\n",
    "    sections = [t.section(interval.begin, interval.end) for t in interval.data]\n",
    "    sections = [s for s in sections if s]\n",
    "    if sections:\n",
    "        for s in sections:\n",
    "            session.add(s)\n",
    "            session.commit()\n",
    "        intervals.append(Interval(interval.begin, interval.end, sections))\n",
    "    else:\n",
    "        print(f\"empty interval {interval.begin} - {interval.end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-29 07:59:25+00:00\t2019-11-29 21:21:10+00:00\t13:21:45\t南紀勝浦温泉 万清楼\n",
      "2019-11-29 21:21:10+00:00\t2019-11-29 21:21:11+00:00\t0:00:01\t南紀勝浦温泉 万清楼\n",
      "2019-11-29 21:21:11+00:00\t2019-11-29 22:54:04+00:00\t1:32:53\t南紀勝浦温泉 万清楼\n",
      "2019-11-29 22:54:27+00:00\t2019-11-29 22:55:15+00:00\t0:00:48\t2019-11-30 2.json.gz\n",
      "2019-11-29 22:55:15+00:00\t2019-11-29 23:02:14+00:00\t0:06:59\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-29 23:02:18+00:00\t2019-11-29 23:02:19+00:00\t0:00:01\tKii-Katsuura Station (紀伊勝浦駅)\n",
      "2019-11-29 23:02:19+00:00\t2019-11-29 23:04:46+00:00\t0:02:27\tKii-Katsuura Station (紀伊勝浦駅) Aneel Nazareth (9931878)\n",
      "2019-11-29 23:04:46+00:00\t2019-11-29 23:04:47+00:00\t0:00:01\tKii-Katsuura Station (紀伊勝浦駅) Aneel Nazareth (9931878)\n",
      "2019-11-29 23:04:47+00:00\t2019-11-29 23:20:59+00:00\t0:16:12\tKii-Katsuura Station (紀伊勝浦駅) Aneel Nazareth (9931878)\n",
      "2019-11-29 23:20:59+00:00\t2019-11-29 23:21:00+00:00\t0:00:01\t熊野交通 勝浦駅前出札所\n",
      "2019-11-29 23:21:00+00:00\t2019-11-29 23:24:52+00:00\t0:03:52\tKii-Katsuura Station (紀伊勝浦駅) Aneel Nazareth (9931878)\n",
      "2019-11-29 23:24:55+00:00\t2019-11-29 23:46:00+00:00\t0:21:05\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-29 23:46:00+00:00\t2019-11-29 23:46:06+00:00\t0:00:06\tAneel Nazareth (9931878)\n",
      "2019-11-29 23:46:06+00:00\t2019-11-29 23:46:07+00:00\t0:00:01\tDaimonzaka 2019-11-30 2.json.gz\n",
      "2019-11-29 23:46:07+00:00\t2019-11-29 23:48:48+00:00\t0:02:41\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-29 23:48:48+00:00\t2019-11-29 23:48:54+00:00\t0:00:06\tAneel Nazareth (9931878)\n",
      "2019-11-29 23:48:54+00:00\t2019-11-29 23:49:24+00:00\t0:00:30\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-29 23:49:24+00:00\t2019-11-29 23:49:25+00:00\t0:00:01\tDaimonzaka\n",
      "2019-11-29 23:49:25+00:00\t2019-11-29 23:57:08+00:00\t0:07:43\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-29 23:57:14+00:00\t2019-11-29 23:57:15+00:00\t0:00:01\t396, Nachisan 2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-29 23:57:15+00:00\t2019-11-30 00:00:08+00:00\t0:02:53\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:00:13+00:00\t2019-11-30 00:01:30+00:00\t0:01:17\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:01:30+00:00\t2019-11-30 00:01:34+00:00\t0:00:04\tAneel Nazareth (9931878)\n",
      "2019-11-30 00:01:34+00:00\t2019-11-30 00:01:35+00:00\t0:00:01\t2019-11-30 2.json.gz 396, Nachisan\n",
      "2019-11-30 00:01:35+00:00\t2019-11-30 00:04:18+00:00\t0:02:43\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:04:18+00:00\t2019-11-30 00:04:24+00:00\t0:00:06\tAneel Nazareth (9931878)\n",
      "2019-11-30 00:04:24+00:00\t2019-11-30 00:06:49+00:00\t0:02:25\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:06:51+00:00\t2019-11-30 00:06:52+00:00\t0:00:01\t2019-11-30 2.json.gz 447, Nachisan\n",
      "2019-11-30 00:06:52+00:00\t2019-11-30 00:09:25+00:00\t0:02:33\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:09:29+00:00\t2019-11-30 00:36:29+00:00\t0:27:00\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:36:29+00:00\t2019-11-30 00:36:33+00:00\t0:00:04\tAneel Nazareth (9931878)\n",
      "2019-11-30 00:36:33+00:00\t2019-11-30 00:36:34+00:00\t0:00:01\tAneel Nazareth (9931878) 2019-11-30 2.json.gz 156-1, Nachisan\n",
      "2019-11-30 00:36:34+00:00\t2019-11-30 00:39:08+00:00\t0:02:34\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:39:08+00:00\t2019-11-30 00:39:12+00:00\t0:00:04\tAneel Nazareth (9931878)\n",
      "2019-11-30 00:39:12+00:00\t2019-11-30 00:45:02+00:00\t0:05:50\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:45:02+00:00\t2019-11-30 00:45:03+00:00\t0:00:01\tKumano Nachi Taisha (熊野那智大社) 2019-11-30 2.json.gz\n",
      "2019-11-30 00:45:03+00:00\t2019-11-30 00:46:24+00:00\t0:01:21\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:46:24+00:00\t2019-11-30 00:46:28+00:00\t0:00:04\tAneel Nazareth (9931878)\n",
      "2019-11-30 00:46:28+00:00\t2019-11-30 00:46:29+00:00\t0:00:01\t1, Nachisan 2019-11-30 2.json.gz\n",
      "2019-11-30 00:46:29+00:00\t2019-11-30 00:49:17+00:00\t0:02:48\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:49:21+00:00\t2019-11-30 00:49:22+00:00\t0:00:01\t1, Nachisan 2019-11-30 2.json.gz\n",
      "2019-11-30 00:49:22+00:00\t2019-11-30 00:54:11+00:00\t0:04:49\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 00:54:11+00:00\t2019-11-30 00:54:22+00:00\t0:00:11\tAneel Nazareth (9931878)\n",
      "2019-11-30 00:54:22+00:00\t2019-11-30 00:54:23+00:00\t0:00:01\tSeiganto-ji 2019-11-30 2.json.gz\n",
      "2019-11-30 00:54:23+00:00\t2019-11-30 01:06:54+00:00\t0:12:31\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 01:06:57+00:00\t2019-11-30 01:13:05+00:00\t0:06:08\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 01:13:09+00:00\t2019-11-30 01:13:10+00:00\t0:00:01\tThree Story pagoda 2019-11-30 2.json.gz\n",
      "2019-11-30 01:13:10+00:00\t2019-11-30 01:19:58+00:00\t0:06:48\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 01:19:58+00:00\t2019-11-30 01:20:01+00:00\t0:00:03\tAneel Nazareth (9931878)\n",
      "2019-11-30 01:20:01+00:00\t2019-11-30 01:20:23+00:00\t0:00:22\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 01:20:26+00:00\t2019-11-30 01:20:27+00:00\t0:00:01\tNachisan 2019-11-30 2.json.gz\n",
      "2019-11-30 01:20:27+00:00\t2019-11-30 01:27:11+00:00\t0:06:44\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 01:27:16+00:00\t2019-11-30 01:45:41+00:00\t0:18:25\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 01:45:41+00:00\t2019-11-30 01:45:42+00:00\t0:00:01\tNachi Falls (那智の瀧)\n",
      "2019-11-30 01:45:42+00:00\t2019-11-30 01:49:35+00:00\t0:03:53\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 01:49:35+00:00\t2019-11-30 01:49:43+00:00\t0:00:08\tAneel Nazareth (9931878)\n",
      "2019-11-30 01:49:43+00:00\t2019-11-30 01:49:44+00:00\t0:00:01\t那智の滝前バス停\n",
      "2019-11-30 01:49:44+00:00\t2019-11-30 02:00:27+00:00\t0:10:43\t那智の滝前バス停 Aneel Nazareth (9931878)\n",
      "2019-11-30 02:00:27+00:00\t2019-11-30 02:00:28+00:00\t0:00:01\t那智の滝前バス停\n",
      "2019-11-30 02:00:28+00:00\t2019-11-30 02:09:51+00:00\t0:09:23\t那智の滝前バス停 Aneel Nazareth (9931878)\n",
      "2019-11-30 02:09:51+00:00\t2019-11-30 02:09:57+00:00\t0:00:06\tAneel Nazareth (9931878)\n",
      "2019-11-30 02:09:57+00:00\t2019-11-30 02:32:37+00:00\t0:22:40\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 02:32:37+00:00\t2019-11-30 02:32:46+00:00\t0:00:09\tAneel Nazareth (9931878)\n",
      "2019-11-30 02:32:46+00:00\t2019-11-30 02:33:53+00:00\t0:01:07\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 02:33:53+00:00\t2019-11-30 02:33:54+00:00\t0:00:01\t勝浦駅 バス停 2019-11-30 2.json.gz\n",
      "2019-11-30 02:33:54+00:00\t2019-11-30 02:35:58+00:00\t0:02:04\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 02:37:57+00:00\t2019-11-30 02:37:58+00:00\t0:00:01\tKii-Katsuura Station (紀伊勝浦駅)\n",
      "2019-11-30 02:37:58+00:00\t2019-11-30 02:39:33+00:00\t0:01:35\tKii-Katsuura Station (紀伊勝浦駅)\n",
      "2019-11-30 02:39:33+00:00\t2019-11-30 02:39:34+00:00\t0:00:01\tRIO\n",
      "2019-11-30 02:39:34+00:00\t2019-11-30 03:13:57+00:00\t0:34:23\tKii-Katsuura Station (紀伊勝浦駅) Aneel Nazareth (9931878)\n",
      "2019-11-30 03:13:57+00:00\t2019-11-30 03:13:58+00:00\t0:00:01\tKii-Katsuura Station (紀伊勝浦駅)\n",
      "2019-11-30 03:13:58+00:00\t2019-11-30 03:17:52+00:00\t0:03:54\tKii-Katsuura Station (紀伊勝浦駅) Aneel Nazareth (9931878)\n",
      "2019-11-30 03:18:52+00:00\t2019-11-30 03:18:53+00:00\t0:00:01\t2, Tsukiji 6-Chōme\n",
      "2019-11-30 03:18:56+00:00\t2019-11-30 03:23:37+00:00\t0:04:41\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 03:24:08+00:00\t2019-11-30 03:41:44+00:00\t0:17:36\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 03:41:44+00:00\t2019-11-30 03:41:49+00:00\t0:00:05\tAneel Nazareth (9931878)\n",
      "2019-11-30 03:41:49+00:00\t2019-11-30 03:41:50+00:00\t0:00:01\tShingū 2019-11-30 2.json.gz\n",
      "2019-11-30 03:41:50+00:00\t2019-11-30 03:44:36+00:00\t0:02:46\t2019-11-30 2.json.gz\n",
      "2019-11-30 03:44:43+00:00\t2019-11-30 04:14:12+00:00\t0:29:29\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 04:16:19+00:00\t2019-11-30 04:17:34+00:00\t0:01:15\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 04:17:34+00:00\t2019-11-30 04:19:55+00:00\t0:02:21\tAneel Nazareth (9931878)\n",
      "2019-11-30 04:19:55+00:00\t2019-11-30 06:15:02+00:00\t1:55:07\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 06:15:06+00:00\t2019-11-30 06:16:05+00:00\t0:00:59\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 06:16:05+00:00\t2019-11-30 06:16:13+00:00\t0:00:08\tAneel Nazareth (9931878)\n",
      "2019-11-30 06:16:13+00:00\t2019-11-30 06:29:44+00:00\t0:13:31\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 06:29:51+00:00\t2019-11-30 06:37:30+00:00\t0:07:39\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 06:37:32+00:00\t2019-11-30 07:12:21+00:00\t0:34:49\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 07:12:21+00:00\t2019-11-30 07:12:30+00:00\t0:00:09\tAneel Nazareth (9931878)\n",
      "2019-11-30 07:12:30+00:00\t2019-11-30 07:15:09+00:00\t0:02:39\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 07:15:24+00:00\t2019-11-30 07:15:25+00:00\t0:00:01\t2019-11-30 2.json.gz Shinkansen Nagoya Station (東海道新幹線 名古屋駅)\n",
      "2019-11-30 07:15:25+00:00\t2019-11-30 07:15:32+00:00\t0:00:07\t2019-11-30 2.json.gz\n",
      "2019-11-30 07:15:32+00:00\t2019-11-30 07:15:33+00:00\t0:00:01\tShinkansen Nagoya Station (東海道新幹線 名古屋駅)\n",
      "2019-11-30 07:15:33+00:00\t2019-11-30 07:17:16+00:00\t0:01:43\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 07:17:26+00:00\t2019-11-30 07:17:50+00:00\t0:00:24\t2019-11-30 2.json.gz\n",
      "2019-11-30 07:17:55+00:00\t2019-11-30 07:27:42+00:00\t0:09:47\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 07:27:45+00:00\t2019-11-30 07:27:46+00:00\t0:00:01\t2019-11-30 2.json.gz Unknown Place\n",
      "2019-11-30 07:27:46+00:00\t2019-11-30 07:30:38+00:00\t0:02:52\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 07:30:45+00:00\t2019-11-30 07:44:26+00:00\t0:13:41\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 07:44:36+00:00\t2019-11-30 07:44:37+00:00\t0:00:01\t2019-11-30 2.json.gz Unknown Place\n",
      "2019-11-30 07:44:37+00:00\t2019-11-30 07:51:06+00:00\t0:06:29\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 07:51:36+00:00\t2019-11-30 08:12:46+00:00\t0:21:10\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 08:12:53+00:00\t2019-11-30 08:12:54+00:00\t0:00:01\tShinkansen Kyoto Station (東海道新幹線 京都駅) 2019-11-30 2.json.gz\n",
      "2019-11-30 08:12:54+00:00\t2019-11-30 08:13:28+00:00\t0:00:34\t2019-11-30 2.json.gz\n",
      "2019-11-30 08:13:28+00:00\t2019-11-30 08:13:29+00:00\t0:00:01\tShinkansen Kyoto Station (東海道新幹線 京都駅) 2019-11-30 2.json.gz\n",
      "2019-11-30 08:13:29+00:00\t2019-11-30 08:22:03+00:00\t0:08:34\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 08:22:34+00:00\t2019-11-30 08:33:31+00:00\t0:10:57\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 08:33:31+00:00\t2019-11-30 08:33:33+00:00\t0:00:02\tAneel Nazareth (9931878)\n",
      "2019-11-30 08:33:33+00:00\t2019-11-30 08:33:34+00:00\t0:00:01\t2019-11-30 2.json.gz Hotel Kuu Kyoto (ホテル空) Aneel Nazareth (9931878)\n",
      "2019-11-30 08:33:34+00:00\t2019-11-30 08:34:43+00:00\t0:01:09\t2019-11-30 2.json.gz Aneel Nazareth (9931878)\n",
      "2019-11-30 08:34:43+00:00\t2019-11-30 08:42:35+00:00\t0:07:52\t2019-11-30 2.json.gz\n",
      "2019-11-30 08:42:35+00:00\t2019-11-30 08:42:36+00:00\t0:00:01\tHotel Kuu Kyoto (ホテル空)\n",
      "2019-11-30 08:42:36+00:00\t2019-11-30 09:06:50+00:00\t0:24:14\t2019-11-30 2.json.gz\n",
      "2019-11-30 09:06:53+00:00\t2019-11-30 09:17:09+00:00\t0:10:16\t2019-11-30 2.json.gz\n",
      "2019-11-30 09:17:13+00:00\t2019-11-30 09:17:14+00:00\t0:00:01\tVeg Out 2019-11-30 2.json.gz\n",
      "2019-11-30 09:17:14+00:00\t2019-11-30 09:17:34+00:00\t0:00:20\t2019-11-30 2.json.gz\n",
      "2019-11-30 09:17:34+00:00\t2019-11-30 09:17:35+00:00\t0:00:01\tVeg Out 2019-11-30 2.json.gz\n",
      "2019-11-30 09:17:35+00:00\t2019-11-30 09:51:39+00:00\t0:34:04\t2019-11-30 2.json.gz\n",
      "2019-11-30 09:52:31+00:00\t2019-11-30 09:52:32+00:00\t0:00:01\tKyoto Beer Lab (京都ビアラボ) 2019-11-30 2.json.gz\n",
      "2019-11-30 09:52:32+00:00\t2019-11-30 09:55:37+00:00\t0:03:05\t2019-11-30 2.json.gz\n",
      "2019-11-30 09:55:37+00:00\t2019-11-30 09:55:38+00:00\t0:00:01\tKyoto Beer Lab (京都ビアラボ)\n",
      "2019-11-30 09:55:38+00:00\t2019-11-30 11:11:03+00:00\t1:15:25\t2019-11-30 2.json.gz\n",
      "2019-11-30 11:11:05+00:00\t2019-11-30 11:21:49+00:00\t0:10:44\t2019-11-30 2.json.gz\n",
      "2019-11-30 11:21:55+00:00\t2019-11-30 11:21:56+00:00\t0:00:01\t2019-11-30 2.json.gz Unknown Place Hotel Kuu Kyoto (ホテル空)\n",
      "2019-11-30 11:21:56+00:00\t2019-12-01 00:39:26+00:00\t13:17:30\t2019-11-30 2.json.gz Hotel Kuu Kyoto (ホテル空)\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(intervals):\n",
    "    print(f\"{str(i.begin)}\\t{str(i.end)}\\t{i.end - i.begin}\\t{' '.join(set([t.name or t.filename for t in i.data]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from traitlets import Tuple\n",
    "from palettable.cartocolors.qualitative import Prism_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def track_points_in_interval(track, interval):\n",
    "#    return [p for p in track.points if p.time >= interval.begin and p.time <= interval.end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def points_in_interval(i):\n",
    "#    return (\n",
    "#         session.query(GPSPoint)\n",
    "#             .filter(GPSPoint.time >= i.begin)\n",
    "#             .filter(GPSPoint.time <= i.end)\n",
    "#             .distinct(GPSPoint.time)\n",
    "#             .order_by(GPSPoint.time)\n",
    "#         ).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_out_to_target_bounds(change):\n",
    "    m = change.owner\n",
    "    if m.zoom > 1 and m.target_bounds:\n",
    "        b = m.target_bounds\n",
    "        n = change.new\n",
    "        if (n[0][0] < b[0][0] and n[0][1] < b[0][1] and\n",
    "            n[1][0] > b[1][0] and n[1][1] > b[1][1]):\n",
    "            # bounds are already large enough, so remove the target\n",
    "            m.target_bounds = None\n",
    "    else:\n",
    "        # zoom out\n",
    "        m.zoom = m.zoom - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = Map(center=center(bounds([p.lat_lon for p in t.points for t in day_tracks])))\n",
    "m.observe(zoom_out_to_target_bounds, 'bounds')\n",
    "\n",
    "default_bounds = bounds([p.lat_lon for p in t.points for t in day_tracks])\n",
    "\n",
    "#m\n",
    "#with sc:\n",
    "#    display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tracks_in_interval(m, i):\n",
    "    print(f\"{str(i.begin)}\\t{str(i.end)}\\t{i.end - i.begin}\")\n",
    "    \n",
    "    b = []\n",
    "    markers = []\n",
    "    lines = []\n",
    "    n = 0\n",
    "    for t in i.data:\n",
    "        points = t.points # track_points_in_interval(t, i)\n",
    "        if not points:\n",
    "            continue\n",
    "        print(f\"{t.id}\\t{points[0].localtime}\\t{points[-1].localtime}\\t{points[-1].time - points[0].time}\\t{t.name}\\t{t.filename}\")\n",
    "        color = Prism_10.hex_colors[n % len(Prism_10.hex_colors)]\n",
    "        lat_lons = [p.lat_lon for p in points]\n",
    "        b = bounds(lat_lons + [p for p in b])\n",
    "        if len(points) == 1:\n",
    "            marker = CircleMarker(location=points[0].lat_lon, color=color)\n",
    "            marker.name = f\"{t.id}: {t.name or t.filename or 'Unnamed'}\"\n",
    "            marker.popup = HTML(f\"{t.id}: {t.name or t.filename}<br/>{points[0].time}\")\n",
    "            markers.append(marker)\n",
    "        else:\n",
    "            line = Polyline(locations=lat_lons, fill=False, color=color)\n",
    "            line.name = f\"{t.id}: {t.name or t.filename or 'Unnamed'}\"\n",
    "            line.popup = HTML(f\"{t.id}: {t.name or t.filename}<br/>{t.points[0].time} - {t.points[-1].time}\")\n",
    "            lines.append(line)\n",
    "        n += 1\n",
    "    \n",
    "    m.target_bounds = b or default_bounds\n",
    "    m.center = center(b or default_bounds)\n",
    "    m.zoom = 18\n",
    "     \n",
    "    m.clear_layers()\n",
    "    m.add_layer(basemaps.OpenStreetMap.Mapnik)\n",
    "    if markers:\n",
    "        m.add_layer(MarkerCluster(markers=markers))\n",
    "    for line in lines:\n",
    "        m.add_layer(line)\n",
    "    if i.data:\n",
    "        query = \"\"\"\n",
    "        select id, name, description, source, type, filename from track where id in %(ids)s\n",
    "        \"\"\"\n",
    "        display(pd.read_sql_query(query, engine, params={'ids': tuple([t.id for t in i.data])}))\n",
    "    return i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbc138a9cb741388881e4e5035e514e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='i', options=(('07:59:25', Interval(datetime.datetime(2019, 11, 29,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = interactive(lambda i: show_tracks_in_interval(m, i), \n",
    "                i=[(str(i.begin.time()), i) for i in intervals])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = w.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t.id for t in i.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(t.points) for t in i.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = i.data.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not i.data:\n",
    "    intervals.remove(i)\n",
    "len(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(i.data) for i in sorted(intervals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(t) for t in sorted(intervals)[0].data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(sorted(intervals)[0].begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(sorted(intervals)[0].end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b = w.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = Sidecar(title='Map')\n",
    "with sc:\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(p.track) for p in (session.query(GPSPoint)\n",
    "            .filter(GPSPoint.time >= \"2019-11-29 23:02:14+00:00\")\n",
    "            .filter(GPSPoint.time <= \"2019-11-29 23:02:18+00:00\")\n",
    "            .distinct(GPSPoint.time)\n",
    "            .order_by(GPSPoint.time)\n",
    "        ).all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.target_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b = w.result\n",
    "for z in range(18, 1, -1):\n",
    "    m.zoom = z\n",
    "    print(f\"{z}\\t{m.bounds}\")\n",
    "    if (m.bounds[0][1] < b[0] and m.bounds[0][0] < b[1] and\n",
    "        m.bounds[1][1] > b[2] and m.bounds[1][0] > b[3]):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.zoom = 17\n",
    "m.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpxpy\n",
    "from geopy.distance import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_to_gpx_track(points, tracks):\n",
    "    t = gpxpy.gpx.GPXTrack(\n",
    "            name=f\"{points[0].localtime.time()} {' '.join({t.type or '' for t in tracks})}\",\n",
    "            description=\"\\t\".join({t.description or \"\" for t in tracks}),\n",
    "        )\n",
    "    t.comment=\"\\t\".join({t.name or t.filename or \"\" for t in tracks})\n",
    "    t.source=\"\\t\".join({t.source or \"\" for t in tracks})\n",
    "    t.type=\"\\t\".join({t.type or \"\" for t in tracks})\n",
    "    s = gpxpy.gpx.GPXTrackSegment()\n",
    "    t.segments.append(s)\n",
    "    for p in points:\n",
    "        s.points.append(gpxpy.gpx.GPXTrackPoint(\n",
    "            latitude=p.latitude, longitude=p.longitude, elevation=p.elevation, time=p.time))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUR = timedelta(hours=1)\n",
    "\n",
    "def max_speed(points):\n",
    "    max_s = 0\n",
    "    for j in range(1, len(points)):\n",
    "        d = distance((points[j-1].latitude, points[j-1].longitude),\n",
    "                     (points[j].latitude, points[j].longitude)).miles\n",
    "        t = (points[j].time - points[j-1].time) / HOUR\n",
    "        s = d/(t + 1/3600)\n",
    "        max_s = max(max_s, s)\n",
    "    return max_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx = gpxpy.gpx.GPX()\n",
    "for i in sorted(intervals):\n",
    "    track_ids = [t.id for t in i.data]\n",
    "    track_points = dict()\n",
    "    \n",
    "    for track_id in track_ids:\n",
    "        points = (\n",
    "            session.query(GPSPoint)\n",
    "            .filter(GPSPoint.track_id.in_(track_ids))\n",
    "            .filter(GPSPoint.time.between(i.begin, i.end))\n",
    "            .distinct(GPSPoint.time)\n",
    "            .order_by(GPSPoint.time)\n",
    "        ).all()\n",
    "        if points:\n",
    "            track_points[track_id] = points\n",
    "            \n",
    "    track_ids = sorted(track_points.keys())\n",
    "    if not track_ids:\n",
    "        continue\n",
    "    merged = track_points[track_ids.pop(0)]\n",
    "    merged_speed = max_speed(merged)\n",
    "    unmerged = []\n",
    "    while track_ids:\n",
    "        next_id = track_ids.pop(0)\n",
    "        potential_merge = sorted(merged + track_points[next_id], key=lambda p: p.time)\n",
    "        potential_speed = max_speed(potential_merge)\n",
    "        print(f\"previous speed {merged_speed}\\tnew speed {potential_speed}\\tratio {potential_speed/(merged_speed + 0.0001)}\")\n",
    "        if potential_speed/(merged_speed + 0.0001) < 1.1:\n",
    "            merged = potential_merge\n",
    "            merged_speed = potential_speed\n",
    "        else:\n",
    "            print(\"### NOT MERGING\")\n",
    "            unmerged.append(track_points[next_id])\n",
    "    \n",
    "    for points in [merged] + unmerged:\n",
    "        if len(points) == 1:\n",
    "            p = points[0]\n",
    "            t = p.track\n",
    "            w = gpxpy.gpx.GPXWaypoint(\n",
    "                latitude=p.latitude, longitude=p.longitude, elevation=p.elevation,\n",
    "                time=p.time, name=t.name, description=t.description, type=t.type,\n",
    "                comment=t.source or t.filename\n",
    "            )\n",
    "            gpx.waypoints.append(w)\n",
    "        else:\n",
    "            tracks = {p.track for p in points}\n",
    "            #if len(tracks) > 1:\n",
    "            #    total_d = 0\n",
    "            #    max_s = 0\n",
    "            #    one_hour = timedelta(hours=1)\n",
    "            #    for j in range(1, len(points)):\n",
    "            #        d = distance((points[j-1].latitude, points[j-1].longitude),\n",
    "            #                     (points[j].latitude, points[j].longitude)).miles\n",
    "            #        total_d += d\n",
    "            #        t = (points[j].time - points[j-1].time) / one_hour\n",
    "            #        s = d/t\n",
    "            #        # print(d, t, s)\n",
    "            #        max_s = max(max_s, s)\n",
    "            #    total_t = (points[-1].time - points[0].time) / one_hour\n",
    "            #    avg_s = total_d / total_t\n",
    "            #    print(f\"max speed: {max_s}  avg_speed: {avg_s}\")\n",
    "            #    # speed is too fast, might be pingponging between two tracks, include both\n",
    "            #    if max_s > 100:\n",
    "            #        for track in tracks:\n",
    "            #            track_id = track.id\n",
    "            #            track_points = [p for p in points if p.track_id == track_id]\n",
    "            #            gpx.tracks.append(points_to_gpx_track(track_points, [track]))\n",
    "            #            print(\"filtered track\")\n",
    "            #            gpx.tracks[-1].number = len(gpx.tracks)\n",
    "            gpx.tracks.append(points_to_gpx_track(points, tracks))\n",
    "            gpx.tracks[-1].number = len(gpx.tracks)\n",
    "    print(f\"{str(points[0].localtime)}\\t{str(points[-1].localtime.time())}\\t{i.end - i.begin}\\t{len(points)}\\t{set(t.name or t.filename for t in i.data)}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{date}.gpx\", \"w\") as fh:\n",
    "    print(gpx.to_xml(version=\"1.1\"), file=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in session.query(GPSTrack):\n",
    "    if len(t.points) > 1:\n",
    "        print(f\"{t.id}\\t{max_speed(t.points)}\\t{t.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_query = \"\"\"\n",
    "select time as t1, lag(time) over (order by time) as t2,\n",
    "    latitude as lat1, lag(latitude) over (order by time) as lat2,\n",
    "    longitude as lon1, lag(longitude) over (order by time) as lon2\n",
    "from point\n",
    "where track_id = %(track_id)s\n",
    "order by time\n",
    "\"\"\"\n",
    "speed_df = pd.read_sql_query(speed_query, engine, params={'track_id': 12566})\n",
    "display(speed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df[\"distance\"] = speed_df.dropna().apply(lambda row: distance((row['lat1'], row['lon1']), (row['lat2'], row['lon2'])).miles , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df[\"hours\"] = (speed_df[\"t1\"] - speed_df[\"t2\"]) / HOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df = speed_df[speed_df.hours > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df[\"speed\"] = speed_df[\"distance\"] / speed_df[\"hours\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df.plot.line(x=\"t1\", y=\"speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df.sort_values(by=\"speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df.speed.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from palettable.cartocolors.qualitative import Prism_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import palettable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prism_10.hex_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup identical tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "length_query = \"\"\"\n",
    "select length, array_agg(track_id) as track_ids,\n",
    "array_agg(start) as starts,\n",
    "array_agg(stop) as stops\n",
    "from (\n",
    "select track_id, count(*) as length, min(time) as start, max(time) as stop \n",
    "from point\n",
    "group by track_id) x\n",
    "group by length\n",
    "order by length\n",
    "\"\"\"\n",
    "length_df = pd.read_sql_query(length_query, engine)\n",
    "length_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_are_same(p1, p2):\n",
    "    return (p1.time == p2.time and\n",
    "            p1.latitude == p2.latitude and\n",
    "            p1.longitude == p2.longitude and\n",
    "            p1.elevation == p2.elevation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why do we have multiple points in the same second?\n",
    "def ultrasort(points):\n",
    "    return sorted(points, key=lambda p: (p.time, p.latitude, p.longitude, p.elevation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = []\n",
    "for row in length_df.itertuples():\n",
    "    track_ids = row.track_ids\n",
    "    starts = row.starts\n",
    "    stops = row.stops\n",
    "    by_times = defaultdict(list)\n",
    "    for (start, stop, track_id) in zip(starts, stops, track_ids):\n",
    "        by_times[(start, stop)].append(track_id)\n",
    "    # print(f\"{len(track_ids)} tracks with {len(by_times)} unique time bounds\")\n",
    "    for bounds, tracks_ids in by_times.items():\n",
    "        if len(tracks_ids) > 1:\n",
    "            tracks_ids.sort()\n",
    "            uniques = [session.query(GPSTrack).get(tracks_ids[0])]\n",
    "            for track_id in tracks_ids[1:]:\n",
    "                t = session.query(GPSTrack).get(track_id)\n",
    "                for u in uniques:\n",
    "                    \n",
    "                    for p1, p2 in zip(ultrasort(u.points), ultrasort(t.points)):\n",
    "                        if not points_are_same(p1, p2):\n",
    "                            break # not the same as this unique\n",
    "                    else:\n",
    "                        # all points matched, so this is a duplicate\n",
    "                        print(f\"{row.length}: {track_id} is a duplicate of {u.id}\")\n",
    "                        print(f\"{u.id}\\t{u.name}\\t{u.filename}\\t{u.source}\\t{u.parent}\")\n",
    "                        print(f\"{t.id}\\t{t.name}\\t{t.filename}\\t{t.source}\\t{t.parent}\")\n",
    "                        print()\n",
    "                        dupes.append(t)\n",
    "                        break\n",
    "                else:\n",
    "                    # no u matched\n",
    "                    uniques.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t.id for t in dupes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in dupes:\n",
    "    session.delete(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"delete from track where id = 1417\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select * from track where id in (15100, 15099)\n",
    "\"\"\"\n",
    "pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select * from track where id in (2492, 12385)\n",
    "\"\"\"\n",
    "pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intvs = [i for i in intervals if 15099 in [t.id for t in i.data] or 15100 in [t.id for t in i.data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = session.query(GPSTrack).get(2492)\n",
    "b = session.query(GPSTrack).get(12385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a.points), str(a.start.time), str(a.end.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b.points), str(b.start.time), str(b.end.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p1, p2 in zip(a.points, b.points):\n",
    "    if not points_are_same(p1, p2):\n",
    "        print(p1.time, p2.time,\n",
    "            p1.latitude, p2.latitude,\n",
    "            p1.longitude, p2.longitude,\n",
    "            p1.elevation, p2.elevation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
